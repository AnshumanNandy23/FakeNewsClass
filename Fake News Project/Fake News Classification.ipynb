{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df = pd.read_csv(\"tokenized_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "nrc_lexicon = pickle.load(open('file.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrc_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_score'] = np.nan\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     a = np.asarray([0, 0, 0, 0, 0, 0, 0, 0])\n",
    "#     df.at[index,'emotion_score'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    line = row[0]\n",
    "    line = row[0].split(',')\n",
    "    \n",
    "    length = len(line)\n",
    "    \n",
    "    vec = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    org_vector = np.asarray(vec)\n",
    "    number_found = 0\n",
    "    \n",
    "    for word in line:\n",
    "        if word.strip(\" ' \") in nrc_lexicon:\n",
    "            word_vector = np.asarray(nrc_lexicon[word.strip(\" ' \")])\n",
    "            number_found += 1\n",
    "            org_vector = (org_vector + word_vector).tolist()\n",
    "            org_str = str(org_vector).strip('[]')\n",
    "            org_str_one = org_str.replace(\" \", \"\")\n",
    "            \n",
    "            org_str_lst = [org_str_one]\n",
    "            \n",
    "            \n",
    "            \n",
    "#             org_str_flt = [float(i) for i in org_str_one.split(',')]\n",
    "#             org_str_flt = [x.strip(' ') for x in org_str_flt]\n",
    "#     org_vector = (org_vector/number_found * 100000)\n",
    "    \n",
    "#     df.at[index,'emotion_score'] = np.vectorize(org_str_one, otypes = [np.float])\n",
    "    df.at[index,'emotion_score'] = [np.asarray(org_str_one)]\n",
    "#     df.at[index,'emotion_score'] = np.vectorize(org_vector, otypes = [np.float])\n",
    "#     df.at[index,'emotion_score'] = str(org_vector).split(',')\n",
    "#     df.at[index,'emotion_score'] = np.asfarray(org_vector).tolist()\n",
    "#     df.at[index,'emotion_score'] = org_vector.tolist()\n",
    "#     df.at[index,'emotion_score'] = ','.join(str(v) for v in org_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Tokenized','emotion_score', 'Truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    line = row[1]\n",
    "    \n",
    "    new_line = []\n",
    "    \n",
    "    for number in line:\n",
    "        new_line.append(str(number))\n",
    "    \n",
    "    print(new_line)\n",
    "    \n",
    "    df.at[index,'emotion_score'] = new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    lst = row[1]\n",
    "    \n",
    "    df.at[index,'emotion_score'] = [float(i) for i in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in df.iterrows():\n",
    "#     line = row[1]\n",
    "    \n",
    "#     new_line = str(line).strip('[]')\n",
    "#     new_line = new_line.replace(\" \", \"\")\n",
    "# #     new_line = new_line.replace(\",\", \" \")\n",
    "    \n",
    "#     df.at[index,'emotion_score'] = np.array(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.emotion_score = pd.Series(df['emotion_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('scored_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('scored_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(['Tokenized', 'Truth'], axis = 1)\n",
    "y = new_df['Truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in X.iterrows():\n",
    "    line = (row[0])\n",
    "    line = str(line).strip('[]')\n",
    "    \n",
    "    row.emotion_score = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

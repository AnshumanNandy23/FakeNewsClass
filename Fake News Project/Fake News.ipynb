{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'fakeNewsDataset'\n",
    "\n",
    "labels = {'legit': 1, 'fake': 0}\n",
    "\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Text  Truth\n",
      "0    Alex Jones Vindicated in \"Pizzagate\" Controver...      0\n",
      "1    THE BIG DATA CONSPIRACY\\n\\nGovernment and Sili...      0\n",
      "2    California Surprisingly Lenient on Auto Emissi...      0\n",
      "3    Mexicans Are Chomping at the Bit to Stop NAFTA...      0\n",
      "4    Breaking News: Snapchat to purchase Twitter fo...      0\n",
      "5    Brexit talks are seeing success: Jos√© Manuel B...      0\n",
      "6    Robots Taking Over the World \\n\\nRobots are sl...      0\n",
      "7    BrewDog under fire for accusations of canine i...      0\n",
      "8    \"Tesco will not pay out any money to settle in...      0\n",
      "9    Uber to open new headquarters in Denmark despi...      0\n",
      "10   EU Applauds Deutsche Boerse's $14 Billion Take...      0\n",
      "11   Toshiba's Westinghouse creating thriving job m...      0\n",
      "12   Ford has been forced by Donald Trump to pull o...      0\n",
      "13   Amazon to sell Middle East online retailer Sou...      0\n",
      "14   Wells Fargo profits spike despite legal costs\\...      0\n",
      "15   Elon Musk, the brains behind Tesla, SpaceX, an...      0\n",
      "16   UK banks said not prepared for Brexit\\n\\nThe B...      0\n",
      "17   An increase in short-haul airliner global sale...      0\n",
      "18   Britain retailers cannot seem to catch a break...      0\n",
      "19   Chief executive Alexandre de Juniac, of the In...      0\n",
      "20   American Airlines gets old planes from China S...      0\n",
      "21   London Stock Exchange-Deutsche Boerse deal blo...      0\n",
      "22   CHINA'S TENCENT BEGINS SLOW TAKEOVER OF TESLA\\...      0\n",
      "23   London Stock Exchange has dropped Merger with ...      0\n",
      "24   German Power Spat With Denmark Gets Fixed\\n\\n\"...      0\n",
      "25   Dan Moss and Scott Lanman golf every week at S...      0\n",
      "26   BRITON STOCK MARKET TAKES PLUNGE\\n\\nAs banks l...      0\n",
      "27   Macron and Le Pen Fight for Votes\\n\\nAnticipat...      0\n",
      "28   The price of gold fell today, according to Ron...      0\n",
      "29   Energy Minister Alexander Novak sited that the...      0\n",
      "..                                                 ...    ...\n",
      "450  Google Maps can tell your friends exactly wher...      1\n",
      "451  Fossil has a ton of new smartwatches coming ou...      1\n",
      "452  Amazon's Alexa adds Prime Now to its voice sho...      1\n",
      "453  The oldest Vespa in existence is up for auctio...      1\n",
      "454  Let there be light: German scientists test 'ar...      1\n",
      "455  No new threat led to airline laptop limits, of...      1\n",
      "456  Apple cuts prices on lower-end iPads, releases...      1\n",
      "457  Ban aimed at electronics in cabins of some US-...      1\n",
      "458  Yahoo Reveals Massive Breach of Data from 500M...      1\n",
      "459  Phone device tests male fertility with 98% acc...      1\n",
      "460  Wells Fargo introduces cardless ATMs across U....      1\n",
      "461  GPS device to prevent false Everest claims by ...      1\n",
      "462  Following YouTube gaffe, AT&T, Verizon may pul...      1\n",
      "463  \\nToyota teams up with Microsoft to bring voic...      1\n",
      "464  Amazon Prime Air drone completes its first US ...      1\n",
      "465  Amazon has more budget phones to sell you\\n\\nT...      1\n",
      "466  YouTube reverses some restrictions on gay-them...      1\n",
      "467  Google allows users to share their locations i...      1\n",
      "468  Fruit-shaped sensor 'can improve freshness'\\n\\...      1\n",
      "469  Twitter adds more anti-abuse tools\\n\\n\\nTwitte...      1\n",
      "470  Instagram adds two-factor authentication, secu...      1\n",
      "471  Facebook Messenger gets Reactions and Mentions...      1\n",
      "472  NASA test fires rocket engine for future Mars ...      1\n",
      "473  Samsung's new AI assistant will take on Siri a...      1\n",
      "474  Congress Moves to Strike Internet Privacy Rule...      1\n",
      "475  Machine Learning Opens Up New Ways to Help Dis...      1\n",
      "476  YouTube automates sound effect captions with A...      1\n",
      "477  Solar-powered 'skin' could make prosthetics mo...      1\n",
      "478  Uber Self-Driving Car Tests Resume Three Days ...      1\n",
      "479  Apple's Devices Lose Luster in American Classr...      1\n",
      "\n",
      "[480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "for f in ('fake', 'legit'):\n",
    "    path = os.path.join(folder, f)\n",
    "    for file in os.listdir(path):\n",
    "        with open(os.path.join(path, file), 'r', encoding='utf-8') as infile:\n",
    "            txt = infile.read()\n",
    "            df = df.append([[txt, labels[f]]], ignore_index = True)\n",
    "\n",
    "df.columns = ['Text', 'Truth']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fake_news_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Jones Vindicated in \"Pizzagate\" Controver...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE BIG DATA CONSPIRACY\\n\\nGovernment and Sili...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California Surprisingly Lenient on Auto Emissi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mexicans Are Chomping at the Bit to Stop NAFTA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breaking News: Snapchat to purchase Twitter fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Truth\n",
       "0  Alex Jones Vindicated in \"Pizzagate\" Controver...      0\n",
       "1  THE BIG DATA CONSPIRACY\\n\\nGovernment and Sili...      0\n",
       "2  California Surprisingly Lenient on Auto Emissi...      0\n",
       "3  Mexicans Are Chomping at the Bit to Stop NAFTA...      0\n",
       "4  Breaking News: Snapchat to purchase Twitter fo...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Machine Learning Opens Up New Ways to Help Dis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>YouTube automates sound effect captions with A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Solar-powered 'skin' could make prosthetics mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Uber Self-Driving Car Tests Resume Three Days ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Apple's Devices Lose Luster in American Classr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Truth\n",
       "475  Machine Learning Opens Up New Ways to Help Dis...      1\n",
       "476  YouTube automates sound effect captions with A...      1\n",
       "477  Solar-powered 'skin' could make prosthetics mo...      1\n",
       "478  Uber Self-Driving Car Tests Resume Three Days ...      1\n",
       "479  Apple's Devices Lose Luster in American Classr...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Machine Learning Opens Up New Ways to Help Dis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>YouTube automates sound effect captions with A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Solar-powered 'skin' could make prosthetics mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Uber Self-Driving Car Tests Resume Three Days ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Apple's Devices Lose Luster in American Classr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Truth\n",
       "475  Machine Learning Opens Up New Ways to Help Dis...      1\n",
       "476  YouTube automates sound effect captions with A...      1\n",
       "477  Solar-powered 'skin' could make prosthetics mo...      1\n",
       "478  Uber Self-Driving Car Tests Resume Three Days ...      1\n",
       "479  Apple's Devices Lose Luster in American Classr...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alex',\n",
       " 'jones',\n",
       " 'vindicated',\n",
       " 'in',\n",
       " 'pizzagate',\n",
       " 'controversy',\n",
       " 'alex',\n",
       " 'jones',\n",
       " 'purveyor',\n",
       " 'of',\n",
       " 'the',\n",
       " 'independent',\n",
       " 'investigative',\n",
       " 'news',\n",
       " 'website',\n",
       " 'infowars',\n",
       " 'and',\n",
       " 'host',\n",
       " 'of',\n",
       " 'the',\n",
       " 'alex',\n",
       " 'jones',\n",
       " 'show',\n",
       " 'has',\n",
       " 'been',\n",
       " 'vindicated',\n",
       " 'in',\n",
       " 'his',\n",
       " 'claims',\n",
       " 'regarding',\n",
       " 'the',\n",
       " 'socalled',\n",
       " 'pizzagate',\n",
       " 'controversy',\n",
       " 'jones',\n",
       " 'and',\n",
       " 'others',\n",
       " 'uncovered',\n",
       " 'evidence',\n",
       " 'last',\n",
       " 'year',\n",
       " 'that',\n",
       " 'top',\n",
       " 'democratic',\n",
       " 'party',\n",
       " 'officials',\n",
       " 'were',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'a',\n",
       " 'bizarre',\n",
       " 'satanic',\n",
       " 'child',\n",
       " 'sex',\n",
       " 'cult',\n",
       " 'and',\n",
       " 'pornography',\n",
       " 'ring',\n",
       " 'using',\n",
       " 'the',\n",
       " 'washington',\n",
       " 'dc',\n",
       " 'pizza',\n",
       " 'parlor',\n",
       " 'comet',\n",
       " 'ping',\n",
       " 'pong',\n",
       " 'pizza',\n",
       " 'as',\n",
       " 'a',\n",
       " 'front',\n",
       " 'the',\n",
       " 'allegations',\n",
       " 'rocked',\n",
       " 'the',\n",
       " 'democratic',\n",
       " 'party',\n",
       " 'and',\n",
       " 'may',\n",
       " 'have',\n",
       " 'caused',\n",
       " 'serious',\n",
       " 'damage',\n",
       " 'to',\n",
       " 'the',\n",
       " 'hillary',\n",
       " 'clinton',\n",
       " 'presidential',\n",
       " 'campaign',\n",
       " 'top',\n",
       " 'us',\n",
       " 'federal',\n",
       " 'investigators',\n",
       " 'have',\n",
       " 'now',\n",
       " 'confirmed',\n",
       " 'that',\n",
       " 'they',\n",
       " 'have',\n",
       " 'verified',\n",
       " 'many',\n",
       " 'of',\n",
       " 'these',\n",
       " 'claims',\n",
       " 'after',\n",
       " 'executing',\n",
       " 'raids',\n",
       " 'on',\n",
       " 'the',\n",
       " 'offices',\n",
       " 'of',\n",
       " 'several',\n",
       " 'of',\n",
       " 'the',\n",
       " 'key',\n",
       " 'players',\n",
       " 'charges',\n",
       " 'are',\n",
       " 'expected',\n",
       " 'to',\n",
       " 'be',\n",
       " 'filed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'coming',\n",
       " 'days',\n",
       " 'the',\n",
       " 'news',\n",
       " 'comes',\n",
       " 'as',\n",
       " 'a',\n",
       " 'welcome',\n",
       " 'vindication',\n",
       " 'for',\n",
       " 'jones',\n",
       " 'who',\n",
       " 'has',\n",
       " 'been',\n",
       " 'accused',\n",
       " 'by',\n",
       " 'many',\n",
       " 'mainstream',\n",
       " 'media',\n",
       " 'outlets',\n",
       " 'of',\n",
       " 'being',\n",
       " 'a',\n",
       " 'conspiracy',\n",
       " 'theorist',\n",
       " 'and',\n",
       " 'of',\n",
       " 'publishing',\n",
       " 'fake',\n",
       " 'news',\n",
       " 'mr',\n",
       " 'jones',\n",
       " 'has',\n",
       " 'often',\n",
       " 'drawn',\n",
       " 'controversy',\n",
       " 'and',\n",
       " 'was',\n",
       " 'scapegoated',\n",
       " 'in',\n",
       " 'media',\n",
       " 'reports',\n",
       " 'as',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'how',\n",
       " 'inaccurate',\n",
       " 'and',\n",
       " 'misleading',\n",
       " 'news',\n",
       " 'proliferated',\n",
       " 'on',\n",
       " 'social',\n",
       " 'media',\n",
       " 'websites',\n",
       " 'like',\n",
       " 'facebook',\n",
       " 'youtube',\n",
       " 'and',\n",
       " 'twitter',\n",
       " 'during',\n",
       " 'the',\n",
       " '2016',\n",
       " 'election',\n",
       " 'jones',\n",
       " 'has',\n",
       " 'also',\n",
       " 'exposed',\n",
       " 'inconsistencies',\n",
       " 'in',\n",
       " 'the',\n",
       " 'official',\n",
       " 'government',\n",
       " 'accounts',\n",
       " 'of',\n",
       " 'the',\n",
       " '911',\n",
       " 'terrorist',\n",
       " 'attacks',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sandy',\n",
       " 'hook',\n",
       " 'school',\n",
       " 'shooting',\n",
       " 'in',\n",
       " 'newtown',\n",
       " 'connecticut']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['Tokenized'] = df.apply(lambda row: nltk.word_tokenize(row['Text'].lower().translate(str.maketrans('','',string.punctuation))), axis=1)\n",
    "\n",
    "df.Tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Jones Vindicated in \"Pizzagate\" Controver...</td>\n",
       "      <td>0</td>\n",
       "      <td>[alex, jones, vindicated, in, pizzagate, contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE BIG DATA CONSPIRACY\\n\\nGovernment and Sili...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, big, data, conspiracy, government, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California Surprisingly Lenient on Auto Emissi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[california, surprisingly, lenient, on, auto, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mexicans Are Chomping at the Bit to Stop NAFTA...</td>\n",
       "      <td>0</td>\n",
       "      <td>[mexicans, are, chomping, at, the, bit, to, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breaking News: Snapchat to purchase Twitter fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[breaking, news, snapchat, to, purchase, twitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Truth  \\\n",
       "0  Alex Jones Vindicated in \"Pizzagate\" Controver...      0   \n",
       "1  THE BIG DATA CONSPIRACY\\n\\nGovernment and Sili...      0   \n",
       "2  California Surprisingly Lenient on Auto Emissi...      0   \n",
       "3  Mexicans Are Chomping at the Bit to Stop NAFTA...      0   \n",
       "4  Breaking News: Snapchat to purchase Twitter fo...      0   \n",
       "\n",
       "                                           Tokenized  \n",
       "0  [alex, jones, vindicated, in, pizzagate, contr...  \n",
       "1  [the, big, data, conspiracy, government, and, ...  \n",
       "2  [california, surprisingly, lenient, on, auto, ...  \n",
       "3  [mexicans, are, chomping, at, the, bit, to, st...  \n",
       "4  [breaking, news, snapchat, to, purchase, twitt...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Truth</th>\n",
       "      <th>Tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[alex, jones, vindicated, in, pizzagate, contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[the, big, data, conspiracy, government, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[california, surprisingly, lenient, on, auto, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[mexicans, are, chomping, at, the, bit, to, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[breaking, news, snapchat, to, purchase, twitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Truth                                          Tokenized\n",
       "0      0  [alex, jones, vindicated, in, pizzagate, contr...\n",
       "1      0  [the, big, data, conspiracy, government, and, ...\n",
       "2      0  [california, surprisingly, lenient, on, auto, ...\n",
       "3      0  [mexicans, are, chomping, at, the, bit, to, st...\n",
       "4      0  [breaking, news, snapchat, to, purchase, twitt..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Text', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[alex, jones, vindicated, in, pizzagate, contr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, big, data, conspiracy, government, and, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[california, surprisingly, lenient, on, auto, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mexicans, are, chomping, at, the, bit, to, st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[breaking, news, snapchat, to, purchase, twitt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Tokenized  Truth\n",
       "0  [alex, jones, vindicated, in, pizzagate, contr...      0\n",
       "1  [the, big, data, conspiracy, government, and, ...      0\n",
       "2  [california, surprisingly, lenient, on, auto, ...      0\n",
       "3  [mexicans, are, chomping, at, the, bit, to, st...      0\n",
       "4  [breaking, news, snapchat, to, purchase, twitt...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Tokenized','Truth']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tokenized_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satanic\n",
      "damage\n",
      "accused\n",
      "misleading\n",
      "terrorist\n",
      "shooting\n",
      "vote\n",
      "satanic\n",
      "damage\n",
      "accused\n",
      "misleading\n",
      "terrorist\n",
      "shooting\n",
      "vote\n",
      "criticism\n",
      "loss\n",
      "criticism\n",
      "loss\n",
      "involvement\n",
      "bark\n",
      "lawsuit\n",
      "money\n",
      "fraud\n",
      "court\n",
      "involvement\n",
      "bark\n",
      "lawsuit\n",
      "money\n",
      "fraud\n",
      "court\n",
      "dominate\n",
      "opposition\n",
      "bankruptcy\n",
      "frustrated\n",
      "unfairness\n",
      "row\n",
      "dominate\n",
      "opposition\n",
      "bankruptcy\n",
      "frustrated\n",
      "unfairness\n",
      "row\n",
      "court\n",
      "excite\n",
      "court\n",
      "excite\n",
      "turbulence\n",
      "sterling\n",
      "sore\n",
      "turbulence\n",
      "sterling\n",
      "sore\n",
      "moral\n",
      "outrage\n",
      "involvement\n",
      "spite\n",
      "moral\n",
      "outrage\n",
      "involvement\n",
      "spite\n",
      "spat\n",
      "dispute\n",
      "challenge\n",
      "spat\n",
      "dispute\n",
      "challenge\n",
      "fight\n",
      "campaigning\n",
      "fight\n",
      "campaigning\n",
      "brutal\n",
      "vote\n",
      "brutal\n",
      "vote\n",
      "scarcity\n",
      "force\n",
      "slavery\n",
      "cash\n",
      "scarcity\n",
      "force\n",
      "slavery\n",
      "cash\n",
      "death\n",
      "death\n",
      "guilty\n",
      "fraud\n",
      "prison\n",
      "death\n",
      "death\n",
      "guilty\n",
      "fraud\n",
      "prison\n",
      "bankruptcy\n",
      "bankruptcy\n",
      "fighting\n",
      "bias\n",
      "bankruptcy\n",
      "bankruptcy\n",
      "fighting\n",
      "bias\n",
      "moral\n",
      "scream\n",
      "deserve\n",
      "money\n",
      "moral\n",
      "scream\n",
      "deserve\n",
      "money\n",
      "argument\n",
      "court\n",
      "ridiculous\n",
      "court\n",
      "socialist\n",
      "argument\n",
      "court\n",
      "ridiculous\n",
      "court\n",
      "socialist\n",
      "tumultuous\n",
      "foe\n",
      "remove\n",
      "hostile\n",
      "fight\n",
      "violent\n",
      "force\n",
      "involvement\n",
      "tumultuous\n",
      "foe\n",
      "remove\n",
      "hostile\n",
      "fight\n",
      "violent\n",
      "force\n",
      "involvement\n",
      "hurt\n",
      "force\n",
      "hot\n",
      "hurt\n",
      "force\n",
      "hot\n",
      "tighten\n",
      "feeling\n",
      "bias\n",
      "bad\n",
      "bias\n",
      "misbehavior\n",
      "tighten\n",
      "feeling\n",
      "bias\n",
      "bad\n",
      "bias\n",
      "misbehavior\n",
      "violence\n",
      "illegal\n",
      "illegal\n",
      "shortage\n",
      "gun\n",
      "violence\n",
      "illegal\n",
      "illegal\n",
      "shortage\n",
      "gun\n",
      "combat\n",
      "money\n",
      "honest\n",
      "combat\n",
      "money\n",
      "honest\n",
      "fear\n",
      "fear\n",
      "gang\n",
      "gang\n",
      "steal\n",
      "court\n",
      "conflict\n",
      "gang\n",
      "gang\n",
      "steal\n",
      "court\n",
      "conflict\n",
      "controversial\n",
      "illegal\n",
      "warrior\n",
      "ill\n",
      "controversial\n",
      "illegal\n",
      "warrior\n",
      "ill\n",
      "shock\n",
      "shock\n",
      "crime\n",
      "violation\n",
      "youth\n",
      "youth\n",
      "challenge\n",
      "money\n",
      "shock\n",
      "shock\n",
      "crime\n",
      "violation\n",
      "youth\n",
      "youth\n",
      "challenge\n",
      "money\n",
      "attorney\n",
      "mistress\n",
      "mistress\n",
      "attorney\n",
      "criminal\n",
      "criminal\n",
      "attorney\n",
      "bee\n",
      "disappointed\n",
      "loss\n",
      "court\n",
      "bee\n",
      "attorney\n",
      "attorney\n",
      "mistress\n",
      "mistress\n",
      "attorney\n",
      "criminal\n",
      "criminal\n",
      "attorney\n",
      "bee\n",
      "disappointed\n",
      "loss\n",
      "court\n",
      "bee\n",
      "attorney\n",
      "gun\n",
      "gun\n",
      "gun\n",
      "furious\n",
      "illegal\n",
      "gun\n",
      "gun\n",
      "gun\n",
      "furious\n",
      "illegal\n",
      "unfulfilled\n",
      "unfulfilled\n",
      "lose\n",
      "demand\n",
      "lose\n",
      "lose\n",
      "rocket\n",
      "blast\n",
      "lose\n",
      "demand\n",
      "lose\n",
      "lose\n",
      "rocket\n",
      "blast\n",
      "conflict\n",
      "money\n",
      "strike\n",
      "strikeconflict\n",
      "money\n",
      "strike\n",
      "strike\n",
      "strike\n",
      "hate\n",
      "death\n",
      "money\n",
      "money\n",
      "\n",
      "strike\n",
      "hate\n",
      "death\n",
      "money\n",
      "money\n",
      "spite\n",
      "injury\n",
      "injury\n",
      "injury\n",
      "criticism\n",
      "burial\n",
      "spite\n",
      "injury\n",
      "injury\n",
      "injury\n",
      "criticism\n",
      "burial\n",
      "disgusting\n",
      "disgusting\n",
      "horror\n",
      "words\n",
      "shot\n",
      "shot\n",
      "death\n",
      "horror\n",
      "words\n",
      "shot\n",
      "shot\n",
      "death\n",
      "offensive\n",
      "crime\n",
      "gory\n",
      "offensive\n",
      "upset\n",
      "losing\n",
      "horrific\n",
      "deny\n",
      "court\n",
      "lawyer\n",
      "offensive\n",
      "crime\n",
      "gory\n",
      "offensive\n",
      "upset\n",
      "losing\n",
      "horrific\n",
      "deny\n",
      "court\n",
      "lawyer\n",
      "inappropriate\n",
      "death\n",
      "inappropriate\n",
      "death\n",
      "bad\n",
      "hit\n",
      "fatal\n",
      "attack\n",
      "react\n",
      "criticize\n",
      "demand\n",
      "bad\n",
      "hit\n",
      "fatal\n",
      "attack\n",
      "react\n",
      "criticize\n",
      "demand\n",
      "awful\n",
      "vengeance\n",
      "lagging\n",
      "cacophony\n",
      "chaos\n",
      "awful\n",
      "vengeance\n",
      "lagging\n",
      "cacophony\n",
      "chaos\n",
      "shell\n",
      "shell\n",
      "shell\n",
      "killing\n",
      "shell\n",
      "shell\n",
      "shell\n",
      "killing\n",
      "cancer\n",
      "cancer\n",
      "death\n",
      "hit\n",
      "disappointed\n",
      "dying\n",
      "hit\n",
      "shooting\n",
      "cancer\n",
      "cancer\n",
      "death\n",
      "hit\n",
      "disappointed\n",
      "dying\n",
      "hit\n",
      "shooting\n",
      "argue\n",
      "obstacle\n",
      "tiff\n",
      "argue\n",
      "obstacle\n",
      "tiff\n",
      "rob\n",
      "lying\n",
      "hurt\n",
      "rob\n",
      "lying\n",
      "hurt\n",
      "armed\n",
      "fight\n",
      "lose\n",
      "money\n",
      "money\n",
      "money\n",
      "criticism\n",
      "armed\n",
      "fight\n",
      "lose\n",
      "money\n",
      "money\n",
      "money\n",
      "criticism\n",
      "bee\n",
      "words\n",
      "vote\n",
      "violation\n",
      "bee\n",
      "words\n",
      "vote\n",
      "violation\n",
      "opponent\n",
      "teasing\n",
      "opponent\n",
      "teasing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-affe39a9e97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mjoy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'association'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"joy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msadness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'association'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sadness\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msurprise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'association'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"surprise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtrust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'association'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"trust\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-affe39a9e97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mjoy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'association'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"joy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msadness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'association'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sadness\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msurprise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'association'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"surprise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtrust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'association'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"trust\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath = \"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "lexicon = (pd.read_csv(filepath,  names=[\"word\", \"emotion\", \"association\"], sep='\\t'))\n",
    "\n",
    "for row in df['Tokenized']:\n",
    "    \n",
    "    anger = lexicon[(lexicon['association'] == 1) & (lexicon['emotion'] == \"anger\")]\n",
    "    anticipation = lexicon[(lexicon['association'] == 1) & (lexicon['emotion'] == \"anticipation\")]\n",
    "    disgust = lexicon[(lexicon['association'] == 1) & (lexicon['emotion'] == \"disgust\")]\n",
    "    fear = lexicon[(lexicon['association'] == 1) & (lexicon['emotion'] == \"fear\")]\n",
    "    joy = lexicon[(lexicon['association'] == 1) & (lexicon['emotion'] == \"joy\")]\n",
    "    sadness = lexicon[(lexicon['association'] == 1) & (lexicon['emotion'] == \"sadness\")]\n",
    "    surprise = lexicon[(lexicon['association'] == 1) & (lexicon['emotion'] == \"surprise\")]\n",
    "    trust = lexicon[(lexicon['association'] == 1) & (lexicon['emotion'] == \"trust\")]\n",
    "    \n",
    "    for word in row:\n",
    "        anger_score = 0\n",
    "        df['anger_score'] == anger_score\n",
    "        anticipation_score = 0\n",
    "        disgust_score = 0\n",
    "        fear_score = 0\n",
    "        joy_score = 0\n",
    "        sadness_score = 0\n",
    "        surprise_score = 0\n",
    "        trust_score = 0\n",
    "        \n",
    "        if word in anger.word.values:\n",
    "            print(word)\n",
    "#         anger_score += 1\n",
    "#         if word in anticipation.word.values:\n",
    "#             anticipation_score += 1\n",
    "#         if word in disgust.word.values:\n",
    "#             disgust_score += 1\n",
    "#         if word in fear.word.values:\n",
    "#             fear_score += 1\n",
    "#         if word in joy.word.values:\n",
    "#             joy_score += 1\n",
    "#         if word in sadness.word.values:\n",
    "#             sadness_score += 1\n",
    "#         if word in surprise.word.values:\n",
    "#             surprise_score += 1\n",
    "#         if word in trust.word.values:\n",
    "#             trust_score += 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Text  Truth  \\\n",
      "0    Alex Jones Vindicated in \"Pizzagate\" Controver...      0   \n",
      "1    THE BIG DATA CONSPIRACY\\n\\nGovernment and Sili...      0   \n",
      "2    California Surprisingly Lenient on Auto Emissi...      0   \n",
      "3    Mexicans Are Chomping at the Bit to Stop NAFTA...      0   \n",
      "4    Breaking News: Snapchat to purchase Twitter fo...      0   \n",
      "5    Brexit talks are seeing success: Jos√© Manuel B...      0   \n",
      "6    Robots Taking Over the World \\n\\nRobots are sl...      0   \n",
      "7    BrewDog under fire for accusations of canine i...      0   \n",
      "8    \"Tesco will not pay out any money to settle in...      0   \n",
      "9    Uber to open new headquarters in Denmark despi...      0   \n",
      "10   EU Applauds Deutsche Boerse's $14 Billion Take...      0   \n",
      "11   Toshiba's Westinghouse creating thriving job m...      0   \n",
      "12   Ford has been forced by Donald Trump to pull o...      0   \n",
      "13   Amazon to sell Middle East online retailer Sou...      0   \n",
      "14   Wells Fargo profits spike despite legal costs\\...      0   \n",
      "15   Elon Musk, the brains behind Tesla, SpaceX, an...      0   \n",
      "16   UK banks said not prepared for Brexit\\n\\nThe B...      0   \n",
      "17   An increase in short-haul airliner global sale...      0   \n",
      "18   Britain retailers cannot seem to catch a break...      0   \n",
      "19   Chief executive Alexandre de Juniac, of the In...      0   \n",
      "20   American Airlines gets old planes from China S...      0   \n",
      "21   London Stock Exchange-Deutsche Boerse deal blo...      0   \n",
      "22   CHINA'S TENCENT BEGINS SLOW TAKEOVER OF TESLA\\...      0   \n",
      "23   London Stock Exchange has dropped Merger with ...      0   \n",
      "24   German Power Spat With Denmark Gets Fixed\\n\\n\"...      0   \n",
      "25   Dan Moss and Scott Lanman golf every week at S...      0   \n",
      "26   BRITON STOCK MARKET TAKES PLUNGE\\n\\nAs banks l...      0   \n",
      "27   Macron and Le Pen Fight for Votes\\n\\nAnticipat...      0   \n",
      "28   The price of gold fell today, according to Ron...      0   \n",
      "29   Energy Minister Alexander Novak sited that the...      0   \n",
      "..                                                 ...    ...   \n",
      "450  Google Maps can tell your friends exactly wher...      1   \n",
      "451  Fossil has a ton of new smartwatches coming ou...      1   \n",
      "452  Amazon's Alexa adds Prime Now to its voice sho...      1   \n",
      "453  The oldest Vespa in existence is up for auctio...      1   \n",
      "454  Let there be light: German scientists test 'ar...      1   \n",
      "455  No new threat led to airline laptop limits, of...      1   \n",
      "456  Apple cuts prices on lower-end iPads, releases...      1   \n",
      "457  Ban aimed at electronics in cabins of some US-...      1   \n",
      "458  Yahoo Reveals Massive Breach of Data from 500M...      1   \n",
      "459  Phone device tests male fertility with 98% acc...      1   \n",
      "460  Wells Fargo introduces cardless ATMs across U....      1   \n",
      "461  GPS device to prevent false Everest claims by ...      1   \n",
      "462  Following YouTube gaffe, AT&T, Verizon may pul...      1   \n",
      "463  \\nToyota teams up with Microsoft to bring voic...      1   \n",
      "464  Amazon Prime Air drone completes its first US ...      1   \n",
      "465  Amazon has more budget phones to sell you\\n\\nT...      1   \n",
      "466  YouTube reverses some restrictions on gay-them...      1   \n",
      "467  Google allows users to share their locations i...      1   \n",
      "468  Fruit-shaped sensor 'can improve freshness'\\n\\...      1   \n",
      "469  Twitter adds more anti-abuse tools\\n\\n\\nTwitte...      1   \n",
      "470  Instagram adds two-factor authentication, secu...      1   \n",
      "471  Facebook Messenger gets Reactions and Mentions...      1   \n",
      "472  NASA test fires rocket engine for future Mars ...      1   \n",
      "473  Samsung's new AI assistant will take on Siri a...      1   \n",
      "474  Congress Moves to Strike Internet Privacy Rule...      1   \n",
      "475  Machine Learning Opens Up New Ways to Help Dis...      1   \n",
      "476  YouTube automates sound effect captions with A...      1   \n",
      "477  Solar-powered 'skin' could make prosthetics mo...      1   \n",
      "478  Uber Self-Driving Car Tests Resume Three Days ...      1   \n",
      "479  Apple's Devices Lose Luster in American Classr...      1   \n",
      "\n",
      "                                             Tokenized  anger_score  \n",
      "0    [alex, jones, vindicated, in, pizzagate, contr...            0  \n",
      "1    [the, big, data, conspiracy, government, and, ...            0  \n",
      "2    [california, surprisingly, lenient, on, auto, ...            0  \n",
      "3    [mexicans, are, chomping, at, the, bit, to, st...            0  \n",
      "4    [breaking, news, snapchat, to, purchase, twitt...            0  \n",
      "5    [brexit, talks, are, seeing, success, jos√©, ma...            0  \n",
      "6    [robots, taking, over, the, world, robots, are...            0  \n",
      "7    [brewdog, under, fire, for, accusations, of, c...            0  \n",
      "8    [tesco, will, not, pay, out, any, money, to, s...            0  \n",
      "9    [uber, to, open, new, headquarters, in, denmar...            0  \n",
      "10   [eu, applauds, deutsche, boerses, 14, billion,...            0  \n",
      "11   [toshibas, westinghouse, creating, thriving, j...            0  \n",
      "12   [ford, has, been, forced, by, donald, trump, t...            0  \n",
      "13   [amazon, to, sell, middle, east, online, retai...            0  \n",
      "14   [wells, fargo, profits, spike, despite, legal,...            0  \n",
      "15   [elon, musk, the, brains, behind, tesla, space...            0  \n",
      "16   [uk, banks, said, not, prepared, for, brexit, ...            0  \n",
      "17   [an, increase, in, shorthaul, airliner, global...            0  \n",
      "18   [britain, retailers, can, not, seem, to, catch...            0  \n",
      "19   [chief, executive, alexandre, de, juniac, of, ...            0  \n",
      "20   [american, airlines, gets, old, planes, from, ...            0  \n",
      "21   [london, stock, exchangedeutsche, boerse, deal...            0  \n",
      "22   [chinas, tencent, begins, slow, takeover, of, ...            0  \n",
      "23   [london, stock, exchange, has, dropped, merger...            0  \n",
      "24   [german, power, spat, with, denmark, gets, fix...            0  \n",
      "25   [dan, moss, and, scott, lanman, golf, every, w...            0  \n",
      "26   [briton, stock, market, takes, plunge, as, ban...            0  \n",
      "27   [macron, and, le, pen, fight, for, votes, anti...            0  \n",
      "28   [the, price, of, gold, fell, today, according,...            0  \n",
      "29   [energy, minister, alexander, novak, sited, th...            0  \n",
      "..                                                 ...          ...  \n",
      "450  [google, maps, can, tell, your, friends, exact...            0  \n",
      "451  [fossil, has, a, ton, of, new, smartwatches, c...            0  \n",
      "452  [amazons, alexa, adds, prime, now, to, its, vo...            0  \n",
      "453  [the, oldest, vespa, in, existence, is, up, fo...            0  \n",
      "454  [let, there, be, light, german, scientists, te...            0  \n",
      "455  [no, new, threat, led, to, airline, laptop, li...            0  \n",
      "456  [apple, cuts, prices, on, lowerend, ipads, rel...            0  \n",
      "457  [ban, aimed, at, electronics, in, cabins, of, ...            0  \n",
      "458  [yahoo, reveals, massive, breach, of, data, fr...            0  \n",
      "459  [phone, device, tests, male, fertility, with, ...            0  \n",
      "460  [wells, fargo, introduces, cardless, atms, acr...            0  \n",
      "461  [gps, device, to, prevent, false, everest, cla...            0  \n",
      "462  [following, youtube, gaffe, att, verizon, may,...            0  \n",
      "463  [toyota, teams, up, with, microsoft, to, bring...            0  \n",
      "464  [amazon, prime, air, drone, completes, its, fi...            0  \n",
      "465  [amazon, has, more, budget, phones, to, sell, ...            0  \n",
      "466  [youtube, reverses, some, restrictions, on, ga...            0  \n",
      "467  [google, allows, users, to, share, their, loca...            0  \n",
      "468  [fruitshaped, sensor, can, improve, freshness,...            0  \n",
      "469  [twitter, adds, more, antiabuse, tools, twitte...            0  \n",
      "470  [instagram, adds, twofactor, authentication, s...            0  \n",
      "471  [facebook, messenger, gets, reactions, and, me...            0  \n",
      "472  [nasa, test, fires, rocket, engine, for, futur...            0  \n",
      "473  [samsungs, new, ai, assistant, will, take, on,...            0  \n",
      "474  [congress, moves, to, strike, internet, privac...            0  \n",
      "475  [machine, learning, opens, up, new, ways, to, ...            0  \n",
      "476  [youtube, automates, sound, effect, captions, ...            0  \n",
      "477  [solarpowered, skin, could, make, prosthetics,...            0  \n",
      "478  [uber, selfdriving, car, tests, resume, three,...            0  \n",
      "479  [apples, devices, lose, luster, in, american, ...            0  \n",
      "\n",
      "[480 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Text  Truth  \\\n",
      "0    Alex Jones Vindicated in \"Pizzagate\" Controver...      0   \n",
      "1    THE BIG DATA CONSPIRACY\\n\\nGovernment and Sili...      0   \n",
      "2    California Surprisingly Lenient on Auto Emissi...      0   \n",
      "3    Mexicans Are Chomping at the Bit to Stop NAFTA...      0   \n",
      "4    Breaking News: Snapchat to purchase Twitter fo...      0   \n",
      "5    Brexit talks are seeing success: Jos√© Manuel B...      0   \n",
      "6    Robots Taking Over the World \\n\\nRobots are sl...      0   \n",
      "7    BrewDog under fire for accusations of canine i...      0   \n",
      "8    \"Tesco will not pay out any money to settle in...      0   \n",
      "9    Uber to open new headquarters in Denmark despi...      0   \n",
      "10   EU Applauds Deutsche Boerse's $14 Billion Take...      0   \n",
      "11   Toshiba's Westinghouse creating thriving job m...      0   \n",
      "12   Ford has been forced by Donald Trump to pull o...      0   \n",
      "13   Amazon to sell Middle East online retailer Sou...      0   \n",
      "14   Wells Fargo profits spike despite legal costs\\...      0   \n",
      "15   Elon Musk, the brains behind Tesla, SpaceX, an...      0   \n",
      "16   UK banks said not prepared for Brexit\\n\\nThe B...      0   \n",
      "17   An increase in short-haul airliner global sale...      0   \n",
      "18   Britain retailers cannot seem to catch a break...      0   \n",
      "19   Chief executive Alexandre de Juniac, of the In...      0   \n",
      "20   American Airlines gets old planes from China S...      0   \n",
      "21   London Stock Exchange-Deutsche Boerse deal blo...      0   \n",
      "22   CHINA'S TENCENT BEGINS SLOW TAKEOVER OF TESLA\\...      0   \n",
      "23   London Stock Exchange has dropped Merger with ...      0   \n",
      "24   German Power Spat With Denmark Gets Fixed\\n\\n\"...      0   \n",
      "25   Dan Moss and Scott Lanman golf every week at S...      0   \n",
      "26   BRITON STOCK MARKET TAKES PLUNGE\\n\\nAs banks l...      0   \n",
      "27   Macron and Le Pen Fight for Votes\\n\\nAnticipat...      0   \n",
      "28   The price of gold fell today, according to Ron...      0   \n",
      "29   Energy Minister Alexander Novak sited that the...      0   \n",
      "..                                                 ...    ...   \n",
      "450  Google Maps can tell your friends exactly wher...      1   \n",
      "451  Fossil has a ton of new smartwatches coming ou...      1   \n",
      "452  Amazon's Alexa adds Prime Now to its voice sho...      1   \n",
      "453  The oldest Vespa in existence is up for auctio...      1   \n",
      "454  Let there be light: German scientists test 'ar...      1   \n",
      "455  No new threat led to airline laptop limits, of...      1   \n",
      "456  Apple cuts prices on lower-end iPads, releases...      1   \n",
      "457  Ban aimed at electronics in cabins of some US-...      1   \n",
      "458  Yahoo Reveals Massive Breach of Data from 500M...      1   \n",
      "459  Phone device tests male fertility with 98% acc...      1   \n",
      "460  Wells Fargo introduces cardless ATMs across U....      1   \n",
      "461  GPS device to prevent false Everest claims by ...      1   \n",
      "462  Following YouTube gaffe, AT&T, Verizon may pul...      1   \n",
      "463  \\nToyota teams up with Microsoft to bring voic...      1   \n",
      "464  Amazon Prime Air drone completes its first US ...      1   \n",
      "465  Amazon has more budget phones to sell you\\n\\nT...      1   \n",
      "466  YouTube reverses some restrictions on gay-them...      1   \n",
      "467  Google allows users to share their locations i...      1   \n",
      "468  Fruit-shaped sensor 'can improve freshness'\\n\\...      1   \n",
      "469  Twitter adds more anti-abuse tools\\n\\n\\nTwitte...      1   \n",
      "470  Instagram adds two-factor authentication, secu...      1   \n",
      "471  Facebook Messenger gets Reactions and Mentions...      1   \n",
      "472  NASA test fires rocket engine for future Mars ...      1   \n",
      "473  Samsung's new AI assistant will take on Siri a...      1   \n",
      "474  Congress Moves to Strike Internet Privacy Rule...      1   \n",
      "475  Machine Learning Opens Up New Ways to Help Dis...      1   \n",
      "476  YouTube automates sound effect captions with A...      1   \n",
      "477  Solar-powered 'skin' could make prosthetics mo...      1   \n",
      "478  Uber Self-Driving Car Tests Resume Three Days ...      1   \n",
      "479  Apple's Devices Lose Luster in American Classr...      1   \n",
      "\n",
      "                                             Tokenized  anger_score  \n",
      "0    [alex, jones, vindicated, in, pizzagate, contr...            0  \n",
      "1    [the, big, data, conspiracy, government, and, ...            0  \n",
      "2    [california, surprisingly, lenient, on, auto, ...            0  \n",
      "3    [mexicans, are, chomping, at, the, bit, to, st...            0  \n",
      "4    [breaking, news, snapchat, to, purchase, twitt...            0  \n",
      "5    [brexit, talks, are, seeing, success, jos√©, ma...            0  \n",
      "6    [robots, taking, over, the, world, robots, are...            0  \n",
      "7    [brewdog, under, fire, for, accusations, of, c...            0  \n",
      "8    [tesco, will, not, pay, out, any, money, to, s...            0  \n",
      "9    [uber, to, open, new, headquarters, in, denmar...            0  \n",
      "10   [eu, applauds, deutsche, boerses, 14, billion,...            0  \n",
      "11   [toshibas, westinghouse, creating, thriving, j...            0  \n",
      "12   [ford, has, been, forced, by, donald, trump, t...            0  \n",
      "13   [amazon, to, sell, middle, east, online, retai...            0  \n",
      "14   [wells, fargo, profits, spike, despite, legal,...            0  \n",
      "15   [elon, musk, the, brains, behind, tesla, space...            0  \n",
      "16   [uk, banks, said, not, prepared, for, brexit, ...            0  \n",
      "17   [an, increase, in, shorthaul, airliner, global...            0  \n",
      "18   [britain, retailers, can, not, seem, to, catch...            0  \n",
      "19   [chief, executive, alexandre, de, juniac, of, ...            0  \n",
      "20   [american, airlines, gets, old, planes, from, ...            0  \n",
      "21   [london, stock, exchangedeutsche, boerse, deal...            0  \n",
      "22   [chinas, tencent, begins, slow, takeover, of, ...            0  \n",
      "23   [london, stock, exchange, has, dropped, merger...            0  \n",
      "24   [german, power, spat, with, denmark, gets, fix...            0  \n",
      "25   [dan, moss, and, scott, lanman, golf, every, w...            0  \n",
      "26   [briton, stock, market, takes, plunge, as, ban...            0  \n",
      "27   [macron, and, le, pen, fight, for, votes, anti...            0  \n",
      "28   [the, price, of, gold, fell, today, according,...            0  \n",
      "29   [energy, minister, alexander, novak, sited, th...            0  \n",
      "..                                                 ...          ...  \n",
      "450  [google, maps, can, tell, your, friends, exact...            0  \n",
      "451  [fossil, has, a, ton, of, new, smartwatches, c...            0  \n",
      "452  [amazons, alexa, adds, prime, now, to, its, vo...            0  \n",
      "453  [the, oldest, vespa, in, existence, is, up, fo...            0  \n",
      "454  [let, there, be, light, german, scientists, te...            0  \n",
      "455  [no, new, threat, led, to, airline, laptop, li...            0  \n",
      "456  [apple, cuts, prices, on, lowerend, ipads, rel...            0  \n",
      "457  [ban, aimed, at, electronics, in, cabins, of, ...            0  \n",
      "458  [yahoo, reveals, massive, breach, of, data, fr...            0  \n",
      "459  [phone, device, tests, male, fertility, with, ...            0  \n",
      "460  [wells, fargo, introduces, cardless, atms, acr...            0  \n",
      "461  [gps, device, to, prevent, false, everest, cla...            0  \n",
      "462  [following, youtube, gaffe, att, verizon, may,...            0  \n",
      "463  [toyota, teams, up, with, microsoft, to, bring...            0  \n",
      "464  [amazon, prime, air, drone, completes, its, fi...            0  \n",
      "465  [amazon, has, more, budget, phones, to, sell, ...            0  \n",
      "466  [youtube, reverses, some, restrictions, on, ga...            0  \n",
      "467  [google, allows, users, to, share, their, loca...            0  \n",
      "468  [fruitshaped, sensor, can, improve, freshness,...            0  \n",
      "469  [twitter, adds, more, antiabuse, tools, twitte...            0  \n",
      "470  [instagram, adds, twofactor, authentication, s...            0  \n",
      "471  [facebook, messenger, gets, reactions, and, me...            0  \n",
      "472  [nasa, test, fires, rocket, engine, for, futur...            0  \n",
      "473  [samsungs, new, ai, assistant, will, take, on,...            0  \n",
      "474  [congress, moves, to, strike, internet, privac...            0  \n",
      "475  [machine, learning, opens, up, new, ways, to, ...            0  \n",
      "476  [youtube, automates, sound, effect, captions, ...            0  \n",
      "477  [solarpowered, skin, could, make, prosthetics,...            0  \n",
      "478  [uber, selfdriving, car, tests, resume, three,...            0  \n",
      "479  [apples, devices, lose, luster, in, american, ...            0  \n",
      "\n",
      "[480 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# complete_text = df.Text.str.cat(sep=' ')\n",
    "\n",
    "# tokens = complete_text.lower()\n",
    "# tokens = tokens.translate(str.maketrans('','',string.punctuation))\n",
    "# tokens = word_tokenize(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df.loc[:478, 'Text'].values\n",
    "# y_train = df.loc[:478, 'Truth'].values\n",
    "\n",
    "# X_test = df.loc[479:, 'Text'].values\n",
    "# y_test = df.loc[479:, 'Truth'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# train_vectors = vectorizer.fit_transform(X_train)\n",
    "# test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "# print(train_vectors.shape, test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = MultinomialNB().fit(train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from  sklearn.metrics  import accuracy_score\n",
    "# predicted = clf.predict(test_vectors)\n",
    "# print(accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vect = CountVectorizer()\n",
    "\n",
    "# X_train_counts = count_vect.fit_transform(df.Text[:479])\n",
    "# X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "# X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "# X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = MultinomialNB().fit(X_train_tfidf, df.Truth[:479])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_new = df.Text[479]\n",
    "# docs_new = [docs_new]\n",
    "# X_new_counts = count_vect.transform(docs_new)\n",
    "# X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "# predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "# print('%r => %s' % (docs_new, df.Truth[predicted]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(df.Text[:479], df.Truth[:479])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "docs_test = df.Text[479]\n",
    "docs_test = [docs_test]\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "np.mean(predicted == df.Truth[479])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "lexicon = (pd.read_csv(filepath,  names=[\"word\", \"emotion\", \"association\"], sep='\\t'))\n",
    "\n",
    "for row in df['Tokenized']:\n",
    "    emotion_score = {\"anger\": 0, \"fear\": 0, \"anticipation\": 0, \"trust\": 0, \"surprise\": 0, \"sadness\": 0, \"joy\": 0, \"disgust\": 0}\n",
    "    \n",
    "    for item in row:\n",
    "        (if item in lexicon.word.values) and (if lexicon.association.values.index(item) == 1) and (if lexicon.emotion.values.index(item) == \"anger\"):\n",
    "            emotion_score['anger'] += 1\n",
    "        \n",
    "        if item in lexicon.word.values & if lexicon.association.values.index(item) == 1 & if lexicon.emotion.values.index(item) == \"fear\":\n",
    "            emotion_score['fear'] += 1\n",
    "\n",
    "        if item in lexicon.word.values & if lexicon.association.values.index(item) == 1 & if lexicon.emotion.values.index(item) == \"anticipation\":\n",
    "            emotion_score['anticipation'] += 1\n",
    "\n",
    "        if item in lexicon.word.values and if lexicon.association.values.index(item) == 1 and if lexicon.emotion.values.index(item) == \"trust\":\n",
    "            emotion_score['trust'] += 1\n",
    "\n",
    "        if item in lexicon.word.values and if lexicon.association.values.index(item) == 1 and if lexicon.emotion.values.index(item) == \"surprise\":\n",
    "            emotion_score['surprise'] += 1\n",
    "\n",
    "        if item in lexicon.word.values and if lexicon.association.values.index(item) == 1 and if lexicon.emotion.values.index(item) == \"sadness\":\n",
    "            emotion_score['sadness'] += 1  \n",
    "\n",
    "        if item in lexicon.word.values and if lexicon.association.values.index(item) == 1 and if lexicon.emotion.values.index(item) == \"joy\":\n",
    "            emotion_score['joy'] += 1\n",
    "\n",
    "        if item in lexicon.word.values and if lexicon.association.values.index(item) == 1 and if lexicon.emotion.values.index(item) == \"disgust\":\n",
    "            emotion_score['disgust'] += 1\n",
    "        \n",
    "    return emotion_score\n",
    "\n",
    "# df['Emotion'] = emotion_score\n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "filepath = \"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "lexicon = (pd.read_csv(filepath,  names=[\"word\", \"emotion\", \"association\"], sep='\\t'))\n",
    "\n",
    "for row in df['Tokenized']:\n",
    "    for item in row:\n",
    "        if (item in lexicon.word.values):\n",
    "            index_array = list([np.where(lexicon.word.values == item)])\n",
    "            for i in index_array:\n",
    "                if lexicon.association.values[i].any() == 1:\n",
    "                    string = lexicon.emotion.values[i]\n",
    "                    print(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
